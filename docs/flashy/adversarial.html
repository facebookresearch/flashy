<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>flashy.adversarial API documentation</title>
<meta name="description" content="For training adversarial losses, we provide an AdversarialLoss wrapper that encapsulate
the training of the adversarial loss. This allows us to keep …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>flashy.adversarial</code></h1>
</header>
<section id="section-intro">
<p>For training adversarial losses, we provide an AdversarialLoss wrapper that encapsulate
the training of the adversarial loss. This allows us to keep the main training loop simple and
to encapsulate the complexity of the adversarial loss training inside this utility class.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.
#
# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.
&#34;&#34;&#34;For training adversarial losses, we provide an AdversarialLoss wrapper that encapsulate
the training of the adversarial loss. This allows us to keep the main training loop simple and
to encapsulate the complexity of the adversarial loss training inside this utility class.
&#34;&#34;&#34;
import typing as tp

import torch
from torch import nn
from torch.nn import functional as F

from . import distrib, utils


LossType = tp.Union[nn.Module, tp.Callable[[torch.Tensor, torch.Tensor], torch.Tensor]]


class AdversarialLoss(nn.Module):
    &#34;&#34;&#34;
    This is an example class for handling adversarial losses without requiring to mess up
    the main training loop. This will not fit all use case and will need inheriting
    to extend to more complex use (i.e. gradient penalty, or feature loss).

    Args:
        adversary: this will be used to estimate the logits given the fake and real samples.
            We use the convention that the output is high for fake sample.
        optimizer: optimizer used for training the given module.
        loss: loss function, by default binary_cross_entropy_with_logits.


    Example of usage:

        adv_loss = AdversarialLoss(module, optimizer, loss)
        for real in loader:
            noise = torch.randn(...)
            fake = model(noise)
            adv_loss.train_adv(fake, real)
            loss = adv_loss(fake)
            loss.backward()
    &#34;&#34;&#34;
    def __init__(self, adversary: nn.Module, optimizer: torch.optim.Optimizer,
                 loss: LossType = F.binary_cross_entropy_with_logits):
        super().__init__()
        self.adversary = adversary
        distrib.broadcast_model(adversary)
        self.optimizer = optimizer
        self.loss = loss

    def _save_to_state_dict(self, destination, prefix, keep_vars):
        # Add the optimizer state dict inside our own.
        super()._save_to_state_dict(destination, prefix, keep_vars)
        destination[prefix + &#39;optimizer&#39;] = self.optimizer.state_dict()
        return destination

    def _load_from_state_dict(self, state_dict, prefix, *args, **kwargs):
        # Load optimizer state.
        self.optimizer.load_state_dict(state_dict.pop(prefix + &#39;optimizer&#39;))
        super()._load_from_state_dict(state_dict, prefix, *args, **kwargs)

    def train_adv(self, fake: torch.Tensor, real: torch.Tensor):
        &#34;&#34;&#34;Train the adversary with the given fake and real example.
        This will automatically synchronize gradients (with `flashy.distrib.eager_sync_grad`)
        and call the optimizer.
        &#34;&#34;&#34;

        logit_fake_is_fake = self.adversary(fake.detach())
        logit_real_is_fake = self.adversary(real.detach())
        one = torch.tensor(1., device=fake.device).expand_as(logit_fake_is_fake)
        zero = torch.tensor(0., device=fake.device).expand_as(logit_real_is_fake)
        loss = self.loss(logit_fake_is_fake, one) + self.loss(logit_real_is_fake, zero)

        self.optimizer.zero_grad()
        with distrib.eager_sync_model(self.adversary):
            loss.backward()
        self.optimizer.step()
        return loss

    def forward(self, fake: torch.Tensor):
        &#34;&#34;&#34;Return the loss for the generator, i.e. trying to fool the adversary.
        &#34;&#34;&#34;
        with utils.readonly(self.adversary):
            logit_fake_is_fake = self.adversary(fake)
            zero = torch.tensor(0., device=fake.device).expand_as(logit_fake_is_fake)
            loss_generator = self.loss(logit_fake_is_fake, zero)
        return loss_generator</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="flashy.adversarial.AdversarialLoss"><code class="flex name class">
<span>class <span class="ident">AdversarialLoss</span></span>
<span>(</span><span>adversary: torch.nn.modules.module.Module, optimizer: torch.optim.optimizer.Optimizer, loss: Union[torch.nn.modules.module.Module, Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = &lt;function binary_cross_entropy_with_logits&gt;)</span>
</code></dt>
<dd>
<div class="desc"><p>This is an example class for handling adversarial losses without requiring to mess up
the main training loop. This will not fit all use case and will need inheriting
to extend to more complex use (i.e. gradient penalty, or feature loss).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>adversary</code></strong></dt>
<dd>this will be used to estimate the logits given the fake and real samples.
We use the convention that the output is high for fake sample.</dd>
<dt><strong><code>optimizer</code></strong></dt>
<dd>optimizer used for training the given module.</dd>
<dt><strong><code>loss</code></strong></dt>
<dd>loss function, by default binary_cross_entropy_with_logits.</dd>
</dl>
<p>Example of usage:</p>
<pre><code>adv_loss = AdversarialLoss(module, optimizer, loss)
for real in loader:
    noise = torch.randn(...)
    fake = model(noise)
    adv_loss.train_adv(fake, real)
    loss = adv_loss(fake)
    loss.backward()
</code></pre>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AdversarialLoss(nn.Module):
    &#34;&#34;&#34;
    This is an example class for handling adversarial losses without requiring to mess up
    the main training loop. This will not fit all use case and will need inheriting
    to extend to more complex use (i.e. gradient penalty, or feature loss).

    Args:
        adversary: this will be used to estimate the logits given the fake and real samples.
            We use the convention that the output is high for fake sample.
        optimizer: optimizer used for training the given module.
        loss: loss function, by default binary_cross_entropy_with_logits.


    Example of usage:

        adv_loss = AdversarialLoss(module, optimizer, loss)
        for real in loader:
            noise = torch.randn(...)
            fake = model(noise)
            adv_loss.train_adv(fake, real)
            loss = adv_loss(fake)
            loss.backward()
    &#34;&#34;&#34;
    def __init__(self, adversary: nn.Module, optimizer: torch.optim.Optimizer,
                 loss: LossType = F.binary_cross_entropy_with_logits):
        super().__init__()
        self.adversary = adversary
        distrib.broadcast_model(adversary)
        self.optimizer = optimizer
        self.loss = loss

    def _save_to_state_dict(self, destination, prefix, keep_vars):
        # Add the optimizer state dict inside our own.
        super()._save_to_state_dict(destination, prefix, keep_vars)
        destination[prefix + &#39;optimizer&#39;] = self.optimizer.state_dict()
        return destination

    def _load_from_state_dict(self, state_dict, prefix, *args, **kwargs):
        # Load optimizer state.
        self.optimizer.load_state_dict(state_dict.pop(prefix + &#39;optimizer&#39;))
        super()._load_from_state_dict(state_dict, prefix, *args, **kwargs)

    def train_adv(self, fake: torch.Tensor, real: torch.Tensor):
        &#34;&#34;&#34;Train the adversary with the given fake and real example.
        This will automatically synchronize gradients (with `flashy.distrib.eager_sync_grad`)
        and call the optimizer.
        &#34;&#34;&#34;

        logit_fake_is_fake = self.adversary(fake.detach())
        logit_real_is_fake = self.adversary(real.detach())
        one = torch.tensor(1., device=fake.device).expand_as(logit_fake_is_fake)
        zero = torch.tensor(0., device=fake.device).expand_as(logit_real_is_fake)
        loss = self.loss(logit_fake_is_fake, one) + self.loss(logit_real_is_fake, zero)

        self.optimizer.zero_grad()
        with distrib.eager_sync_model(self.adversary):
            loss.backward()
        self.optimizer.step()
        return loss

    def forward(self, fake: torch.Tensor):
        &#34;&#34;&#34;Return the loss for the generator, i.e. trying to fool the adversary.
        &#34;&#34;&#34;
        with utils.readonly(self.adversary):
            logit_fake_is_fake = self.adversary(fake)
            zero = torch.tensor(0., device=fake.device).expand_as(logit_fake_is_fake)
            loss_generator = self.loss(logit_fake_is_fake, zero)
        return loss_generator</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="flashy.adversarial.AdversarialLoss.call_super_init"><code class="name">var <span class="ident">call_super_init</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="flashy.adversarial.AdversarialLoss.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="flashy.adversarial.AdversarialLoss.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="flashy.adversarial.AdversarialLoss.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, fake: torch.Tensor) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Return the loss for the generator, i.e. trying to fool the adversary.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, fake: torch.Tensor):
    &#34;&#34;&#34;Return the loss for the generator, i.e. trying to fool the adversary.
    &#34;&#34;&#34;
    with utils.readonly(self.adversary):
        logit_fake_is_fake = self.adversary(fake)
        zero = torch.tensor(0., device=fake.device).expand_as(logit_fake_is_fake)
        loss_generator = self.loss(logit_fake_is_fake, zero)
    return loss_generator</code></pre>
</details>
</dd>
<dt id="flashy.adversarial.AdversarialLoss.train_adv"><code class="name flex">
<span>def <span class="ident">train_adv</span></span>(<span>self, fake: torch.Tensor, real: torch.Tensor)</span>
</code></dt>
<dd>
<div class="desc"><p>Train the adversary with the given fake and real example.
This will automatically synchronize gradients (with <code>flashy.distrib.eager_sync_grad</code>)
and call the optimizer.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_adv(self, fake: torch.Tensor, real: torch.Tensor):
    &#34;&#34;&#34;Train the adversary with the given fake and real example.
    This will automatically synchronize gradients (with `flashy.distrib.eager_sync_grad`)
    and call the optimizer.
    &#34;&#34;&#34;

    logit_fake_is_fake = self.adversary(fake.detach())
    logit_real_is_fake = self.adversary(real.detach())
    one = torch.tensor(1., device=fake.device).expand_as(logit_fake_is_fake)
    zero = torch.tensor(0., device=fake.device).expand_as(logit_real_is_fake)
    loss = self.loss(logit_fake_is_fake, one) + self.loss(logit_real_is_fake, zero)

    self.optimizer.zero_grad()
    with distrib.eager_sync_model(self.adversary):
        loss.backward()
    self.optimizer.step()
    return loss</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="flashy" href="index.html">flashy</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="flashy.adversarial.AdversarialLoss" href="#flashy.adversarial.AdversarialLoss">AdversarialLoss</a></code></h4>
<ul class="">
<li><code><a title="flashy.adversarial.AdversarialLoss.call_super_init" href="#flashy.adversarial.AdversarialLoss.call_super_init">call_super_init</a></code></li>
<li><code><a title="flashy.adversarial.AdversarialLoss.dump_patches" href="#flashy.adversarial.AdversarialLoss.dump_patches">dump_patches</a></code></li>
<li><code><a title="flashy.adversarial.AdversarialLoss.forward" href="#flashy.adversarial.AdversarialLoss.forward">forward</a></code></li>
<li><code><a title="flashy.adversarial.AdversarialLoss.train_adv" href="#flashy.adversarial.AdversarialLoss.train_adv">train_adv</a></code></li>
<li><code><a title="flashy.adversarial.AdversarialLoss.training" href="#flashy.adversarial.AdversarialLoss.training">training</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>